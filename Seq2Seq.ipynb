{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0dc7a5",
   "metadata": {
    "id": "cf0dc7a5"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Remove non-alphabetic characters (Data Cleaning)\n",
    "def clean_text(column):\n",
    "\n",
    "    for row in column:\n",
    "        row = re.sub('([A-Z][a-z]+)', r' \\1', re.sub('([A-Z]+)', r' \\1',  str(row))).split()\n",
    "        row = ' '.join(row)\n",
    "        row = re.sub(\"(\\\\t)\", \" \", str(row)).lower()\n",
    "        row = re.sub(\"(\\\\r)\", \" \", str(row)).lower()\n",
    "        row = re.sub(\"(\\\\n)\", \" \", str(row)).lower()\n",
    "\n",
    "    \n",
    "\n",
    "        # Remove the characters - <>()|&©ø\"',;?~*!\n",
    "        row = re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",.\\}`$\\{;@?~*!+=_\\//1234567890]\", \" \", str(row)).lower()\n",
    "        row = re.sub(r\"\\\\b(\\\\w+)(?:\\\\W+\\\\1\\\\b)+\", \"\", str(row)).lower()\n",
    "\n",
    "\n",
    "#         # Replace INC nums to INC_NUM\n",
    "#         row = re.sub(\"([iI][nN][cC]\\d+)\", \"INC_NUM\", str(row)).lower()\n",
    "\n",
    "#         # Replace CM# and CHG# to CM_NUM\n",
    "#         row = re.sub(\"([cC][mM]\\d+)|([cC][hH][gG]\\d+)\", \"CM_NUM\", str(row)).lower()\n",
    "\n",
    "        # Remove punctuations at the end of a word\n",
    "        row = re.sub(\"(\\.\\s+)\", \" \", str(row)).lower()\n",
    "        row = re.sub(\"(\\-\\s+)\", \" \", str(row)).lower()\n",
    "        row = re.sub(\"(\\:\\s+)\", \" \", str(row)).lower()\n",
    "\n",
    "        # Replace any url to only the domain name\n",
    "        try:\n",
    "            url = re.search(r\"((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)\", str(row))\n",
    "            repl_url = url.group(3)\n",
    "            row = re.sub(r\"((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)\", repl_url, str(row))\n",
    "        except:\n",
    "            pass\n",
    "        #row = re.sub('([A-Z][a-z]+)', r' \\1', re.sub('([A-Z]+)', r' \\1',  str(row))).split()\n",
    "        # Remove multiple spaces\n",
    "        row = re.sub(\"(\\s+)\", \" \", str(row)).lower()\n",
    "\n",
    "        # Remove the single character hanging between any two spaces\n",
    "        row = re.sub(\"(\\s+.\\s+)\", \" \", str(row)).lower()\n",
    "        \n",
    "        \n",
    "\n",
    "        yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941dbfc1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25809,
     "status": "ok",
     "timestamp": 1656322043749,
     "user": {
      "displayName": "Anshuman Singh",
      "userId": "06230192885831480549"
     },
     "user_tz": -330
    },
    "id": "941dbfc1",
    "outputId": "3c1ad41d-512c-4bf6-c6d2-4ff622585e7e"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/gdrive\")\n",
    "\n",
    "df_code = pd.read_csv('/content/gdrive/MyDrive/javascript_Sample_Dataset.csv')\n",
    "df_code = df_code[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4c90c8",
   "metadata": {
    "id": "5d4c90c8"
   },
   "outputs": [],
   "source": [
    "df_code_p = df_code[[\"code\",\"docstring\"]]\n",
    "df_code_p=df_code_p[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf05c07",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1656322055643,
     "user": {
      "displayName": "Anshuman Singh",
      "userId": "06230192885831480549"
     },
     "user_tz": -330
    },
    "id": "faf05c07",
    "outputId": "2d447a50-838a-4159-8f28-9b2633387cdc"
   },
   "outputs": [],
   "source": [
    "print (df_code_p[\"docstring\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df7d553",
   "metadata": {
    "id": "7df7d553"
   },
   "outputs": [],
   "source": [
    "processed_code= clean_text(df_code_p['code'])\n",
    "processed_summary = clean_text(df_code_p['docstring'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14670d61",
   "metadata": {
    "id": "14670d61"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from time import time\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser']) \n",
    "\n",
    "# Process text as batches and yield Doc objects in order\n",
    "code = [str(doc) for doc in nlp.pipe(processed_code, batch_size=50)]\n",
    "summary = [ str(doc)  for doc in nlp.pipe(processed_summary, batch_size=50)]\n",
    "\n",
    "#summary = ['_START_ '+ str(doc) + ' _END_' for doc in nlp.pipe(processed_summary, batch_size=50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896b80eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 381,
     "status": "ok",
     "timestamp": 1656322100547,
     "user": {
      "displayName": "Anshuman Singh",
      "userId": "06230192885831480549"
     },
     "user_tz": -330
    },
    "id": "896b80eb",
    "outputId": "1735421e-01c4-4bf0-c633-79127b7a5287"
   },
   "outputs": [],
   "source": [
    "print (summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f1405b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "executionInfo": {
     "elapsed": 373,
     "status": "error",
     "timestamp": 1656322110858,
     "user": {
      "displayName": "Anshuman Singh",
      "userId": "06230192885831480549"
     },
     "user_tz": -330
    },
    "id": "06f1405b",
    "outputId": "3a10a9e2-7e25-4762-bfc7-f7339ff8a6ee"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_code_p['code'] = code\n",
    "df_code_p['docstring'] = summary\n",
    "print(df_code_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b98fcfa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1162,
     "status": "ok",
     "timestamp": 1656307780015,
     "user": {
      "displayName": "Anshuman Singh",
      "userId": "06230192885831480549"
     },
     "user_tz": -330
    },
    "id": "0b98fcfa",
    "outputId": "23527769-b189-4720-da26-f7628ac9d137"
   },
   "outputs": [],
   "source": [
    " import matplotlib.pyplot as plt\n",
    "\n",
    " text_count = []\n",
    " summary_count = []\n",
    "\n",
    "\n",
    " print(df_code_p['code'])\n",
    " for sent in df_code_p['code']:\n",
    "     print (sent)\n",
    "     text_count.append(len(sent.split()))\n",
    "    \n",
    " for sent in df_code_p['docstring']:\n",
    "     summary_count.append(len(sent.split()))\n",
    "\n",
    " graph_df = pd.DataFrame() \n",
    "\n",
    " graph_df['text'] = text_count\n",
    " graph_df['summary'] = summary_count\n",
    "\n",
    " graph_df.hist(bins = 10)\n",
    " plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542b4734",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 412,
     "status": "ok",
     "timestamp": 1656307797651,
     "user": {
      "displayName": "Anshuman Singh",
      "userId": "06230192885831480549"
     },
     "user_tz": -330
    },
    "id": "542b4734",
    "outputId": "44582b0f-01ee-4c8c-d8ab-b3510667e9cb"
   },
   "outputs": [],
   "source": [
    "max_code_len = 100\n",
    "max_summary_len =10\n",
    "\n",
    "\n",
    "# Select the Summaries and Text which fall below max length \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "cleaned_code = np.array(df_code_p['code'])\n",
    "cleaned_summary= np.array(df_code_p['docstring'])\n",
    "\n",
    "short_text = []\n",
    "short_summary = []\n",
    "\n",
    "for i in range(len(cleaned_code)):\n",
    "    if len(cleaned_summary[i].split()) <= max_summary_len and len(cleaned_code[i].split()) <= max_code_len:\n",
    "        short_text.append(cleaned_code[i])\n",
    "        short_summary.append(cleaned_summary[i])\n",
    "        \n",
    "post_code = pd.DataFrame({'code': short_text,'summary': short_summary})\n",
    "\n",
    "post_code.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5fce89",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "executionInfo": {
     "elapsed": 769,
     "status": "ok",
     "timestamp": 1656307803620,
     "user": {
      "displayName": "Anshuman Singh",
      "userId": "06230192885831480549"
     },
     "user_tz": -330
    },
    "id": "ef5fce89",
    "outputId": "6e6cde52-8a4b-440a-f6c8-0dfb8923bc17"
   },
   "outputs": [],
   "source": [
    "post_code['summary'] = post_code['summary'].apply(lambda x: 'sostok ' + x \\\n",
    "        + ' eostok')\n",
    "\n",
    "post_code.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2b3685",
   "metadata": {
    "id": "6e2b3685"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(\n",
    "    np.array(post_code[\"code\"]),\n",
    "    np.array(post_code[\"summary\"]),\n",
    "    test_size=0.15,\n",
    "    random_state=0,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81373b88",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 456,
     "status": "ok",
     "timestamp": 1656307815365,
     "user": {
      "displayName": "Anshuman Singh",
      "userId": "06230192885831480549"
     },
     "user_tz": -330
    },
    "id": "81373b88",
    "outputId": "6b3ce2ac-5e9d-4737-aecf-f5fd4fbd309a"
   },
   "outputs": [],
   "source": [
    "# Tokenize the text to get the vocab count \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Prepare a tokenizer on training data\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_train))\n",
    "\n",
    "threshold = 5\n",
    "\n",
    "cnt_infrequent = 0\n",
    "total_cnt = 0\n",
    "\n",
    "for key, value in x_tokenizer.word_counts.items():\n",
    "    total_cnt = total_cnt + 1\n",
    "    if value < threshold:\n",
    "        cnt_infrequent = cnt_infrequent + 1\n",
    "\n",
    "    \n",
    "print(\"% of not frequent words in vocabulary: \", (cnt_infrequent / total_cnt) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd5d7f3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1656307822128,
     "user": {
      "displayName": "Anshuman Singh",
      "userId": "06230192885831480549"
     },
     "user_tz": -330
    },
    "id": "edd5d7f3",
    "outputId": "0fc3dc44-e286-4578-ea9f-5d5927db9940"
   },
   "outputs": [],
   "source": [
    "# Prepare a tokenizer, again -- by not considering the rare words\n",
    "x_tokenizer = Tokenizer(num_words = total_cnt - cnt_infrequent) \n",
    "x_tokenizer.fit_on_texts(list(x_train))\n",
    "\n",
    "# Convert text sequences to integer sequences \n",
    "x_train_seqs = x_tokenizer.texts_to_sequences(x_train) \n",
    "x_validation_seqs = x_tokenizer.texts_to_sequences(x_validation)\n",
    "print (x_validation_seqs)\n",
    "# Pad zero upto maximum length\n",
    "x_train = pad_sequences(x_train_seqs,  maxlen=max_code_len, padding='post')\n",
    "x_validation = pad_sequences(x_validation_seqs, maxlen=max_code_len, padding='post')\n",
    "\n",
    "# Size of vocabulary (+1 for padding token)\n",
    "x_voc = x_tokenizer.num_words + 1\n",
    "\n",
    "\n",
    "print(\"Size of vocabulary in X = {}\".format(x_voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bd804b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 702,
     "status": "ok",
     "timestamp": 1656307829093,
     "user": {
      "displayName": "Anshuman Singh",
      "userId": "06230192885831480549"
     },
     "user_tz": -330
    },
    "id": "69bd804b",
    "outputId": "60d75639-8d3d-48a0-9be6-79949221fabb"
   },
   "outputs": [],
   "source": [
    "# Prepare a tokenizer on testing data\n",
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_train))\n",
    "\n",
    "threshold = 5\n",
    "\n",
    "cnt_infrequent = 0\n",
    "total_cnt = 0\n",
    "\n",
    "for key, value in y_tokenizer.word_counts.items():\n",
    "    total_cnt = total_cnt + 1\n",
    "    if value < threshold:\n",
    "        cnt_infrequent = cnt_infrequent + 1\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt_infrequent / total_cnt) * 100)\n",
    "\n",
    "# Prepare a tokenizer, again -- by not considering the rare words\n",
    "y_tokenizer = Tokenizer(num_words = total_cnt - cnt_infrequent) \n",
    "y_tokenizer.fit_on_texts(list(y_train))\n",
    "\n",
    "# Convert text sequences to integer sequences \n",
    "y_train_seqs = y_tokenizer.texts_to_sequences(y_train) \n",
    "y_validation_seqs = y_tokenizer.texts_to_sequences(y_validation)\n",
    "\n",
    "# Pad zero upto maximum length\n",
    "y_train = pad_sequences(y_train_seqs,  maxlen=max_summary_len, padding='post')\n",
    "y_validation = pad_sequences(y_validation_seqs, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "# Size of vocabulary (+1 for padding token)\n",
    "y_voc = y_tokenizer.num_words + 1\n",
    "\n",
    "print(\"Size of vocabulary in Y = {}\".format(y_voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2112f5",
   "metadata": {
    "id": "ff2112f5"
   },
   "outputs": [],
   "source": [
    "ind = []\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    cnt = 0\n",
    "    for j in y_train[i]:\n",
    "        if j != 0:\n",
    "            cnt = cnt + 1\n",
    "    if cnt == 2:\n",
    "        ind.append(i)\n",
    "\n",
    "y_train = np.delete(y_train, ind, axis=0)\n",
    "x_train = np.delete(x_train, ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9c60e5",
   "metadata": {
    "id": "2c9c60e5"
   },
   "outputs": [],
   "source": [
    "ind = []\n",
    "for i in range(len(y_validation)):\n",
    "    cnt = 0\n",
    "    for j in y_validation[i]:\n",
    "        if j != 0:\n",
    "            cnt = cnt + 1\n",
    "    if cnt == 2:\n",
    "        ind.append(i)\n",
    "\n",
    "y_validation = np.delete(y_validation, ind, axis=0)\n",
    "x_validation = np.delete(x_validation, ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d696f3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1656307841710,
     "user": {
      "displayName": "Anshuman Singh",
      "userId": "06230192885831480549"
     },
     "user_tz": -330
    },
    "id": "c7d696f3",
    "outputId": "5ba2aa04-8a23-408e-fe28-bcff92f25af8"
   },
   "outputs": [],
   "source": [
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "print(len(x_validation))\n",
    "print(len(y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d729916",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 412,
     "status": "ok",
     "timestamp": 1656307849568,
     "user": {
      "displayName": "Anshuman Singh",
      "userId": "06230192885831480549"
     },
     "user_tz": -330
    },
    "id": "9d729916",
    "outputId": "efc4c8a8-4d85-41e6-bb6c-94bfadf8670f"
   },
   "outputs": [],
   "source": [
    "print((x_train[0]))\n",
    "print((y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fddef96",
   "metadata": {
    "id": "7fddef96"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, \\\n",
    "    Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60d9799",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 956,
     "status": "ok",
     "timestamp": 1656307859310,
     "user": {
      "displayName": "Anshuman Singh",
      "userId": "06230192885831480549"
     },
     "user_tz": -330
    },
    "id": "a60d9799",
    "outputId": "a2f0a420-c2ff-42a9-c4db-52345ce8e2a2"
   },
   "outputs": [],
   "source": [
    "latent_dim = 300\n",
    "embedding_dim = 200\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_code_len, ))\n",
    "\n",
    "# Embedding layer\n",
    "enc_emb = Embedding(x_voc, embedding_dim,\n",
    "                    trainable=True)(encoder_inputs)\n",
    "\n",
    "# Encoder LSTM 1\n",
    "encoder_lstm1 = LSTM(latent_dim, return_sequences=True,\n",
    "                     return_state=True, dropout=0.4,\n",
    "                     recurrent_dropout=0.4)\n",
    "(encoder_output1, state_h1, state_c1) = encoder_lstm1(enc_emb)\n",
    "\n",
    "# Encoder LSTM 2\n",
    "encoder_lstm2 = LSTM(latent_dim, return_sequences=True,\n",
    "                     return_state=True, dropout=0.4,\n",
    "                     recurrent_dropout=0.4)\n",
    "(encoder_output2, state_h2, state_c2) = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# Encoder LSTM 3\n",
    "encoder_lstm3 = LSTM(latent_dim, return_state=True,\n",
    "                     return_sequences=True, dropout=0.4,\n",
    "                     recurrent_dropout=0.4)\n",
    "(encoder_outputs, state_h, state_c) = encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Set up the decoder, using encoder_states as the initial state\n",
    "decoder_inputs = Input(shape=(None, ))\n",
    "\n",
    "# Embedding layer\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# Decoder LSTM\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True,\n",
    "                    return_state=True, dropout=0.4,\n",
    "                    recurrent_dropout=0.2)\n",
    "(decoder_outputs, decoder_fwd_state, decoder_back_state) = \\\n",
    "    decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
    "\n",
    "# Dense layer\n",
    "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33c6653",
   "metadata": {
    "id": "a33c6653"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d424e9f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 213203,
     "status": "ok",
     "timestamp": 1656308085765,
     "user": {
      "displayName": "Anshuman Singh",
      "userId": "06230192885831480549"
     },
     "user_tz": -330
    },
    "id": "0d424e9f",
    "outputId": "4f84172f-b12f-4944-91d1-e3da86ead958"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    [x_train, y_train[:, :-1]],\n",
    "    y_train.reshape(y_train.shape[0], y_train.shape[1], 1)[:, 1:],\n",
    "    epochs=50,\n",
    "    callbacks=[es],\n",
    "    batch_size=128,\n",
    "    validation_data=([x_validation, y_validation[:, :-1]],\n",
    "                     y_validation.reshape(y_validation.shape[0], y_validation.shape[1], 1)[:\n",
    "                     , 1:]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e847593",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 66,
     "status": "ok",
     "timestamp": 1656308085766,
     "user": {
      "displayName": "Anshuman Singh",
      "userId": "06230192885831480549"
     },
     "user_tz": -330
    },
    "id": "6e847593",
    "outputId": "74695d4b-6cf8-4fc3-d948-51cfd6d9ea34"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70a0ceb",
   "metadata": {
    "id": "c70a0ceb"
   },
   "outputs": [],
   "source": [
    "reverse_target_word_index = y_tokenizer.index_word\n",
    "reverse_source_word_index = x_tokenizer.index_word\n",
    "target_word_index = y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63c15dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "error",
     "timestamp": 1656321991690,
     "user": {
      "displayName": "Anshuman Singh",
      "userId": "06230192885831480549"
     },
     "user_tz": -330
    },
    "id": "c63c15dc",
    "outputId": "f8647580-0c6a-4c7e-a7a1-54d877a5c356"
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs,\n",
    "                      state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim, ))\n",
    "decoder_state_input_c = Input(shape=(latent_dim, ))\n",
    "decoder_hidden_state_input = Input(shape=(max_code_len, latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "(decoder_outputs2, state_h2, state_c2) = decoder_lstm(dec_emb2,\n",
    "        initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
    "                      decoder_state_input_h, decoder_state_input_c],\n",
    "                      [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f98b91",
   "metadata": {
    "id": "67f98b91"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "\n",
    "    # Encode the input as state vectors.\n",
    "    (e_out, e_h, e_c) = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1\n",
    "    target_seq = np.zeros((1, 1))\n",
    "\n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index['sostok']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    while not stop_condition:\n",
    "        (output_tokens, h, c) = decoder_model.predict([target_seq]\n",
    "                + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "\n",
    "        if sampled_token != 'eostok':\n",
    "            decoded_sentence += ' ' + sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find the stop word.\n",
    "        if sampled_token == 'eostok' or len(decoded_sentence.split()) \\\n",
    "            >= max_summary_len - 1:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1)\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        (e_h, e_c) = (h, c)\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d54012",
   "metadata": {
    "id": "94d54012"
   },
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString = ''\n",
    "    for i in input_seq:\n",
    "        if i != 0 and i != target_word_index['sostok'] and i \\\n",
    "            != target_word_index['eostok']:\n",
    "            newString = newString + reverse_target_word_index[i] + ' '\n",
    "\n",
    "    return newString\n",
    "\n",
    "\n",
    "# To convert sequence to text\n",
    "def seq2text(input_seq):\n",
    "    newString = ''\n",
    "    for i in input_seq:\n",
    "        if i != 0:\n",
    "            newString = newString + reverse_source_word_index[i] + ' '\n",
    "\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6280097b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "error",
     "timestamp": 1656321978886,
     "user": {
      "displayName": "Anshuman Singh",
      "userId": "06230192885831480549"
     },
     "user_tz": -330
    },
    "id": "6280097b",
    "outputId": "8fff17e1-506b-4ed8-87f1-3af931053b64"
   },
   "outputs": [],
   "source": [
    "for i in range(0, 19):\n",
    "    print ('Code:', seq2text(x_train[i]))\n",
    "    print ('Original summary:', seq2summary(y_train[i]))\n",
    "    print ('Predicted summary:', decode_sequence(x_train[i].reshape(1,\n",
    "           max_code_len)))\n",
    "    print ('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6UKL99iC8Vi",
   "metadata": {
    "id": "c6UKL99iC8Vi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Seq2Seq.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
